{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mineral-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tamil-fetish",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "identified-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for array-handling and plotting\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# let's keep our keras backend tensorflow quiet\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
    "# for testing on CPU\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "# keras imports for the dataset and building our neural network\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "developed-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "absent-average",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unauthorized-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "important-heather",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "sound-lyric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "X_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n",
      "Train matrix shape (60000, 784)\n",
      "Test matrix shape (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "# let's print the shape before we reshape and normalize\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)\n",
    "\n",
    "# building the input vector from the 28x28 pixels\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# print the final input shape ready for training\n",
    "print(\"Train matrix shape\", X_train.shape)\n",
    "print(\"Test matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "involved-shipping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "collect-review",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "brazilian-portable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10,), array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0].shape,Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('relu'))                            \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model and saving metrics in history\n",
    "history = model.fit(X_train, Y_train,\n",
    "          batch_size=128, epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suited-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# saving the model\n",
    "save_dir = \"mnist-results/\"\n",
    "model_name = 'keras_mnist.h5'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(save_dir + \"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(save_dir + \"model-weight.h5\")\n",
    "print(\"Saved model to disk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load json and create model\n",
    "json_file = open(save_dir + 'model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(save_dir + \"model-weight.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-vegetable",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_model = load_model(model_path)\n",
    "loss_and_metrics = mnist_model.evaluate(X_test, Y_test, verbose=2)\n",
    "\n",
    "print(\"Test Loss\", loss_and_metrics[0])\n",
    "print(\"Test Accuracy\", loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and create predictions on the test set\n",
    "mnist_model = load_model(model_path)\n",
    "predicted_classes = mnist_model.predict_classes(X_test)\n",
    "\n",
    "# see which we predicted correctly and which not\n",
    "correct_indices = np.nonzero(predicted_classes == y_test)[0]\n",
    "incorrect_indices = np.nonzero(predicted_classes != y_test)[0]\n",
    "print()\n",
    "print(len(correct_indices),\" classified correctly\")\n",
    "print(len(incorrect_indices),\" classified incorrectly\")\n",
    "\n",
    "# adapt figure size to accomodate 18 subplots\n",
    "plt.rcParams['figure.figsize'] = (7,14)\n",
    "\n",
    "figure_evaluation = plt.figure()\n",
    "\n",
    "# plot 9 correct predictions\n",
    "for i, correct in enumerate(correct_indices[:9]):\n",
    "    plt.subplot(6,3,i+1)\n",
    "    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\n",
    "      \"Predicted: {}, Truth: {}\".format(predicted_classes[correct],\n",
    "                                        y_test[correct]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "# plot 9 incorrect predictions\n",
    "for i, incorrect in enumerate(incorrect_indices[:9]):\n",
    "    plt.subplot(6,3,i+10)\n",
    "    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\n",
    "      \"Predicted {}, Truth: {}\".format(predicted_classes[incorrect], \n",
    "                                       y_test[incorrect]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "figure_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-lincoln",
   "metadata": {},
   "source": [
    "Vitis - AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.load_model(model_path)\n",
    " \n",
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "quantizer = vitis_quantize.VitisQuantizer(model)\n",
    "quantized_model = quantizer.quantize_model(calib_dataset = X_test[1:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "quantized_model.save(save_dir + 'vitis-ai-quantized_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "Quant_model_path = save_dir + 'vitis-ai-quantized_mnist_model.h5'\n",
    "Quant_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-healthcare",
   "metadata": {},
   "source": [
    "Evaluating the Quantized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.quantization.keras import vitis_quantize\n",
    "with vitis_quantize.quantize_scope():\n",
    "    quantized_model = tf.keras.models.load_model(Quant_model_path)\n",
    "quantized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vai_c_tensorflow2 -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "!vai_c_tensorflow2 -m mnist-results/vitis-ai-quantized_mnist_model.h5 -o mnist-results/ -n mnist_XIR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-island",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
